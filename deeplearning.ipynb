{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA load\n",
    "X = pd.read_csv('./content/loan_train_preprocessed.csv')\n",
    "\n",
    "# backward\n",
    "X = X[['term', 'initial_list_status', 'int_rate', \n",
    "'emp_length', 'annual_inc', 'dti', 'delinq_2yrs', \n",
    "'inq_last_6mths', 'revol_util', 'recoveries', \n",
    "'collection_recovery_fee', 'tot_cur_bal', \n",
    "'home_ownershipRENT', 'purposesmall_business', \n",
    "'purposewedding', 'earliest_cr_line2000']]\n",
    "\n",
    "y = pd.read_csv('./content/loan_train_label.csv')\n",
    "y = y.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10240, 16), (10240, 1), (2560, 16), (2560, 1), (3200, 16), (3200, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividing the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.20 )\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.20 )\n",
    "\n",
    "x_train.shape,y_train.shape,x_val.shape,y_val.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2048, input_shape = (len(x_train.columns),), activation='ELU'))\n",
    "model.add(Dense(1024, activation='ELU'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='ELU'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='ELU'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='ELU'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='ELU'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='ELU'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='ELU'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='ELU'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 210ms/step - loss: 0.6728 - accuracy: 0.6011 - f1: 0.5937 - val_loss: 0.5996 - val_accuracy: 0.6750 - val_f1: 0.6344\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.6192 - accuracy: 0.6416 - f1: 0.6180 - val_loss: 0.5915 - val_accuracy: 0.6762 - val_f1: 0.6155\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.5987 - accuracy: 0.6607 - f1: 0.6298 - val_loss: 0.5646 - val_accuracy: 0.6742 - val_f1: 0.6432\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.5844 - accuracy: 0.6604 - f1: 0.6334 - val_loss: 0.5652 - val_accuracy: 0.6750 - val_f1: 0.6764\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.5761 - accuracy: 0.6704 - f1: 0.6503 - val_loss: 0.5578 - val_accuracy: 0.6762 - val_f1: 0.6909\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.5726 - accuracy: 0.6669 - f1: 0.6528 - val_loss: 0.5536 - val_accuracy: 0.6824 - val_f1: 0.6879\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.5668 - accuracy: 0.6751 - f1: 0.6454 - val_loss: 0.5522 - val_accuracy: 0.6781 - val_f1: 0.6812\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.5643 - accuracy: 0.6724 - f1: 0.6606 - val_loss: 0.5545 - val_accuracy: 0.6801 - val_f1: 0.6854\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.5629 - accuracy: 0.6728 - f1: 0.6418 - val_loss: 0.5566 - val_accuracy: 0.6668 - val_f1: 0.6948\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.5638 - accuracy: 0.6736 - f1: 0.6703 - val_loss: 0.5547 - val_accuracy: 0.6859 - val_f1: 0.6603\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 0.5630 - accuracy: 0.6719 - f1: 0.6335 - val_loss: 0.5594 - val_accuracy: 0.6621 - val_f1: 0.6935\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.5646 - accuracy: 0.6771 - f1: 0.6643 - val_loss: 0.5570 - val_accuracy: 0.6703 - val_f1: 0.6882\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 0.5605 - accuracy: 0.6665 - f1: 0.6614 - val_loss: 0.5549 - val_accuracy: 0.6785 - val_f1: 0.6847\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 0.5599 - accuracy: 0.6768 - f1: 0.6514 - val_loss: 0.5558 - val_accuracy: 0.6828 - val_f1: 0.6906\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.5606 - accuracy: 0.6800 - f1: 0.6686 - val_loss: 0.5545 - val_accuracy: 0.6773 - val_f1: 0.6829\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.5620 - accuracy: 0.6747 - f1: 0.6464 - val_loss: 0.5606 - val_accuracy: 0.6711 - val_f1: 0.6949\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.5602 - accuracy: 0.6756 - f1: 0.6643 - val_loss: 0.5557 - val_accuracy: 0.6883 - val_f1: 0.6595\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.5577 - accuracy: 0.6781 - f1: 0.6590 - val_loss: 0.5517 - val_accuracy: 0.6781 - val_f1: 0.6904\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.5578 - accuracy: 0.6719 - f1: 0.6379 - val_loss: 0.5531 - val_accuracy: 0.6793 - val_f1: 0.6851\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.5539 - accuracy: 0.6861 - f1: 0.6846 - val_loss: 0.5517 - val_accuracy: 0.6805 - val_f1: 0.6708\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.5554 - accuracy: 0.6759 - f1: 0.6318 - val_loss: 0.5619 - val_accuracy: 0.6613 - val_f1: 0.6919\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.5544 - accuracy: 0.6766 - f1: 0.6821 - val_loss: 0.5565 - val_accuracy: 0.6801 - val_f1: 0.6765\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.5536 - accuracy: 0.6810 - f1: 0.6588 - val_loss: 0.5521 - val_accuracy: 0.6785 - val_f1: 0.6696\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5515 - accuracy: 0.6840 - f1: 0.6531 - val_loss: 0.5571 - val_accuracy: 0.6773 - val_f1: 0.6909\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.5564 - accuracy: 0.6751 - f1: 0.6647 - val_loss: 0.5573 - val_accuracy: 0.6793 - val_f1: 0.6788\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.5587 - accuracy: 0.6802 - f1: 0.6607 - val_loss: 0.5611 - val_accuracy: 0.6738 - val_f1: 0.6988\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.5569 - accuracy: 0.6780 - f1: 0.6712 - val_loss: 0.5523 - val_accuracy: 0.6805 - val_f1: 0.6739\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.5538 - accuracy: 0.6819 - f1: 0.6579 - val_loss: 0.5545 - val_accuracy: 0.6738 - val_f1: 0.6581\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.5514 - accuracy: 0.6798 - f1: 0.6544 - val_loss: 0.5522 - val_accuracy: 0.6746 - val_f1: 0.6755\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.5522 - accuracy: 0.6811 - f1: 0.6656 - val_loss: 0.5543 - val_accuracy: 0.6809 - val_f1: 0.6752\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5525 - accuracy: 0.6827 - f1: 0.6676 - val_loss: 0.5544 - val_accuracy: 0.6840 - val_f1: 0.6670\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.5497 - accuracy: 0.6832 - f1: 0.6600 - val_loss: 0.5586 - val_accuracy: 0.6809 - val_f1: 0.7022\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.5521 - accuracy: 0.6821 - f1: 0.6589 - val_loss: 0.5510 - val_accuracy: 0.6781 - val_f1: 0.6640\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.5520 - accuracy: 0.6816 - f1: 0.6721 - val_loss: 0.5595 - val_accuracy: 0.6734 - val_f1: 0.6751\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5534 - accuracy: 0.6855 - f1: 0.6606 - val_loss: 0.5610 - val_accuracy: 0.6762 - val_f1: 0.6967\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5528 - accuracy: 0.6812 - f1: 0.6659 - val_loss: 0.5506 - val_accuracy: 0.6816 - val_f1: 0.6692\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.5517 - accuracy: 0.6798 - f1: 0.6673 - val_loss: 0.5509 - val_accuracy: 0.6812 - val_f1: 0.6740\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.5504 - accuracy: 0.6812 - f1: 0.6617 - val_loss: 0.5582 - val_accuracy: 0.6750 - val_f1: 0.6958\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5497 - accuracy: 0.6813 - f1: 0.6702 - val_loss: 0.5538 - val_accuracy: 0.6793 - val_f1: 0.6764\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.5506 - accuracy: 0.6853 - f1: 0.6721 - val_loss: 0.5569 - val_accuracy: 0.6805 - val_f1: 0.6668\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.5508 - accuracy: 0.6832 - f1: 0.6555 - val_loss: 0.5544 - val_accuracy: 0.6793 - val_f1: 0.6922\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.5519 - accuracy: 0.6839 - f1: 0.6683 - val_loss: 0.5558 - val_accuracy: 0.6832 - val_f1: 0.6568\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.5496 - accuracy: 0.6821 - f1: 0.6656 - val_loss: 0.5550 - val_accuracy: 0.6805 - val_f1: 0.6902\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5471 - accuracy: 0.6849 - f1: 0.6583 - val_loss: 0.5556 - val_accuracy: 0.6836 - val_f1: 0.6851\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.5475 - accuracy: 0.6893 - f1: 0.6822 - val_loss: 0.5542 - val_accuracy: 0.6805 - val_f1: 0.6872\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5478 - accuracy: 0.6909 - f1: 0.6712 - val_loss: 0.5559 - val_accuracy: 0.6859 - val_f1: 0.6822\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.5519 - accuracy: 0.6845 - f1: 0.6719 - val_loss: 0.5524 - val_accuracy: 0.6836 - val_f1: 0.6633\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.5454 - accuracy: 0.6916 - f1: 0.6608 - val_loss: 0.5679 - val_accuracy: 0.6695 - val_f1: 0.7080\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.5525 - accuracy: 0.6822 - f1: 0.6754 - val_loss: 0.5564 - val_accuracy: 0.6746 - val_f1: 0.6154\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.5525 - accuracy: 0.6814 - f1: 0.6656 - val_loss: 0.5586 - val_accuracy: 0.6762 - val_f1: 0.6881\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.5494 - accuracy: 0.6868 - f1: 0.6642 - val_loss: 0.5554 - val_accuracy: 0.6758 - val_f1: 0.6849\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.5472 - accuracy: 0.6901 - f1: 0.6771 - val_loss: 0.5573 - val_accuracy: 0.6781 - val_f1: 0.6922\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5441 - accuracy: 0.6886 - f1: 0.6812 - val_loss: 0.5510 - val_accuracy: 0.6879 - val_f1: 0.6719\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.5460 - accuracy: 0.6927 - f1: 0.6681 - val_loss: 0.5605 - val_accuracy: 0.6797 - val_f1: 0.6902\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.5476 - accuracy: 0.6871 - f1: 0.6719 - val_loss: 0.5582 - val_accuracy: 0.6750 - val_f1: 0.6847\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.5466 - accuracy: 0.6892 - f1: 0.6709 - val_loss: 0.5542 - val_accuracy: 0.6777 - val_f1: 0.6728\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5473 - accuracy: 0.6824 - f1: 0.6622 - val_loss: 0.5627 - val_accuracy: 0.6711 - val_f1: 0.6781\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.5497 - accuracy: 0.6889 - f1: 0.6725 - val_loss: 0.5608 - val_accuracy: 0.6703 - val_f1: 0.6778\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.5483 - accuracy: 0.6862 - f1: 0.6761 - val_loss: 0.5606 - val_accuracy: 0.6715 - val_f1: 0.6810\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5501 - accuracy: 0.6843 - f1: 0.6581 - val_loss: 0.5572 - val_accuracy: 0.6789 - val_f1: 0.6889\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.5488 - accuracy: 0.6830 - f1: 0.6569 - val_loss: 0.5560 - val_accuracy: 0.6816 - val_f1: 0.6822\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.5457 - accuracy: 0.6882 - f1: 0.6795 - val_loss: 0.5530 - val_accuracy: 0.6832 - val_f1: 0.6849\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 0.5462 - accuracy: 0.6868 - f1: 0.6667 - val_loss: 0.5591 - val_accuracy: 0.6824 - val_f1: 0.6826\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.5469 - accuracy: 0.6895 - f1: 0.6642 - val_loss: 0.5598 - val_accuracy: 0.6777 - val_f1: 0.6986\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.5454 - accuracy: 0.6886 - f1: 0.6745 - val_loss: 0.5611 - val_accuracy: 0.6785 - val_f1: 0.6784\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.5476 - accuracy: 0.6892 - f1: 0.6766 - val_loss: 0.5540 - val_accuracy: 0.6859 - val_f1: 0.6759\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.5443 - accuracy: 0.6952 - f1: 0.6726 - val_loss: 0.5554 - val_accuracy: 0.6824 - val_f1: 0.6744\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5460 - accuracy: 0.6878 - f1: 0.6579 - val_loss: 0.5633 - val_accuracy: 0.6684 - val_f1: 0.6969\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5470 - accuracy: 0.6913 - f1: 0.6776 - val_loss: 0.5496 - val_accuracy: 0.6883 - val_f1: 0.6612\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5463 - accuracy: 0.6862 - f1: 0.6675 - val_loss: 0.5558 - val_accuracy: 0.6832 - val_f1: 0.6842\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.5443 - accuracy: 0.6941 - f1: 0.6765 - val_loss: 0.5534 - val_accuracy: 0.6859 - val_f1: 0.6934\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.5453 - accuracy: 0.6928 - f1: 0.6732 - val_loss: 0.5515 - val_accuracy: 0.6875 - val_f1: 0.6762\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5450 - accuracy: 0.6938 - f1: 0.6736 - val_loss: 0.5613 - val_accuracy: 0.6699 - val_f1: 0.6975\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.5497 - accuracy: 0.6826 - f1: 0.6705 - val_loss: 0.5573 - val_accuracy: 0.6766 - val_f1: 0.6886\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5462 - accuracy: 0.6912 - f1: 0.6738 - val_loss: 0.5576 - val_accuracy: 0.6777 - val_f1: 0.6922\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5478 - accuracy: 0.6879 - f1: 0.6722 - val_loss: 0.5555 - val_accuracy: 0.6762 - val_f1: 0.6732\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5443 - accuracy: 0.6891 - f1: 0.6728 - val_loss: 0.5569 - val_accuracy: 0.6824 - val_f1: 0.6839\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.5426 - accuracy: 0.6908 - f1: 0.6812 - val_loss: 0.5593 - val_accuracy: 0.6844 - val_f1: 0.6705\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.5437 - accuracy: 0.6924 - f1: 0.6610 - val_loss: 0.5630 - val_accuracy: 0.6738 - val_f1: 0.6849\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.5451 - accuracy: 0.6904 - f1: 0.6754 - val_loss: 0.5597 - val_accuracy: 0.6816 - val_f1: 0.6139\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5435 - accuracy: 0.6896 - f1: 0.6701 - val_loss: 0.5529 - val_accuracy: 0.6852 - val_f1: 0.6929\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.5435 - accuracy: 0.6909 - f1: 0.6514 - val_loss: 0.5536 - val_accuracy: 0.6832 - val_f1: 0.6798\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.5428 - accuracy: 0.6914 - f1: 0.6860 - val_loss: 0.5527 - val_accuracy: 0.6809 - val_f1: 0.6506\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5412 - accuracy: 0.6902 - f1: 0.6671 - val_loss: 0.5623 - val_accuracy: 0.6773 - val_f1: 0.6934\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5422 - accuracy: 0.6897 - f1: 0.6716 - val_loss: 0.5528 - val_accuracy: 0.6867 - val_f1: 0.6730\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.5404 - accuracy: 0.6969 - f1: 0.6789 - val_loss: 0.5596 - val_accuracy: 0.6844 - val_f1: 0.6899\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.5394 - accuracy: 0.6950 - f1: 0.6869 - val_loss: 0.5549 - val_accuracy: 0.6781 - val_f1: 0.6551\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.5416 - accuracy: 0.6950 - f1: 0.6714 - val_loss: 0.5577 - val_accuracy: 0.6855 - val_f1: 0.6984\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.5430 - accuracy: 0.6938 - f1: 0.6712 - val_loss: 0.5525 - val_accuracy: 0.6859 - val_f1: 0.6702\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.5414 - accuracy: 0.6911 - f1: 0.6863 - val_loss: 0.5540 - val_accuracy: 0.6883 - val_f1: 0.6802\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 0.5425 - accuracy: 0.6919 - f1: 0.6670 - val_loss: 0.5539 - val_accuracy: 0.6836 - val_f1: 0.6787\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.5411 - accuracy: 0.6910 - f1: 0.6717 - val_loss: 0.5585 - val_accuracy: 0.6887 - val_f1: 0.6765\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.5399 - accuracy: 0.6941 - f1: 0.6732 - val_loss: 0.5568 - val_accuracy: 0.6805 - val_f1: 0.6674\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.5409 - accuracy: 0.6894 - f1: 0.6710 - val_loss: 0.5536 - val_accuracy: 0.6836 - val_f1: 0.6768\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.5408 - accuracy: 0.6894 - f1: 0.6728 - val_loss: 0.5542 - val_accuracy: 0.6809 - val_f1: 0.6668\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 0.5403 - accuracy: 0.6949 - f1: 0.6841 - val_loss: 0.5573 - val_accuracy: 0.6867 - val_f1: 0.6838\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.5364 - accuracy: 0.6952 - f1: 0.6630 - val_loss: 0.5538 - val_accuracy: 0.6914 - val_f1: 0.6911\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.5408 - accuracy: 0.6948 - f1: 0.6897 - val_loss: 0.5580 - val_accuracy: 0.6789 - val_f1: 0.6411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2365a865c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust the weights of the classes since your dataset is HIGHLY IMBALANCED!\n",
    "class_weight = {0: 1.,\n",
    "                1: 1.}\n",
    "\n",
    "model.fit(x_train.values,\n",
    "         y_train.values,\n",
    "         epochs = 300,\n",
    "         batch_size = 2048,\n",
    "         validation_data = (x_val.values, y_val.values), class_weight=class_weight,\n",
    "         callbacks=[EarlyStopping(monitor='val_f1', mode='max', patience=50, restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Accuracy of the model is: 65.53125 %\n",
      "\n",
      "[[ 825  741]\n",
      " [ 362 1272]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fully Paid       0.70      0.53      0.60      1566\n",
      " Charged Off       0.63      0.78      0.70      1634\n",
      "\n",
      "    accuracy                           0.66      3200\n",
      "   macro avg       0.66      0.65      0.65      3200\n",
      "weighted avg       0.66      0.66      0.65      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model.predict(x_test.values)\n",
    "y_prediction= [1 if i>=0.5 else 0 for i in y_prediction]\n",
    "print(\"The Test Accuracy of the model is: {} %\".format(accuracy_score(y_test.values, y_prediction) * 100.)) \n",
    "print()\n",
    "\n",
    "print(confusion_matrix(y_test.values, y_prediction))\n",
    "print()\n",
    "\n",
    "target_names = ['Fully Paid', 'Charged Off']\n",
    "print(classification_report(y_test, y_prediction, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dataset prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA load\n",
    "target_X = pd.read_csv('./content/loan_test_preprocessed.csv')\n",
    "\n",
    "# backward\n",
    "target_X = target_X[['term', 'initial_list_status', 'int_rate', \n",
    "'emp_length', 'annual_inc', 'dti', 'delinq_2yrs', \n",
    "'inq_last_6mths', 'revol_util', 'recoveries', \n",
    "'collection_recovery_fee', 'tot_cur_bal', \n",
    "'home_ownershipRENT', 'purposesmall_business', \n",
    "'purposewedding', 'earliest_cr_line2000']]\n",
    "\n",
    "target_y = pd.read_csv('./content/loan_test_label.csv')\n",
    "target_y = target_y.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(target_X.values)\n",
    "y_prediction= [1 if i>=0.5 else 0 for i in y_prediction]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c29f24f490fc11ce1e48d89a3d8a10c86c424066fbebe55fdecaa30f8bedbaf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
